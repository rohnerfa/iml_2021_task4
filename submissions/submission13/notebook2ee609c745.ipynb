{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.config.run_functions_eagerly(True)\nimport pandas as pd\nimport numpy as np\n\n#from numpy import asarray\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\n#from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Concatenate, BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom matplotlib import image\nimport matplotlib.pyplot as plt\n\nimport zipfile\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nimport matplotlib as mpl\n\n\nimport os\n#from PIL import Image\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom tqdm import tqdm\nimport shutil\nimport pickle\nfrom tensorflow.keras.models import Model\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\nfrom pathlib import Path\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import mobilenet_v2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-30T19:56:03.193679Z","iopub.execute_input":"2021-05-30T19:56:03.194031Z","iopub.status.idle":"2021-05-30T19:56:03.204388Z","shell.execute_reply.started":"2021-05-30T19:56:03.194002Z","shell.execute_reply":"2021-05-30T19:56:03.203014Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_triplets_path = '../input/triplets/train_triplets.txt'\ntest_triplets_path = '../input/triplets/test_triplets.txt'\nfood_path = '/content/drive/MyDrive/ml_task4/food.zip'\nimage_path = '../input/food-img/food'","metadata":{"execution":{"iopub.status.busy":"2021-05-30T19:57:51.782526Z","iopub.execute_input":"2021-05-30T19:57:51.782841Z","iopub.status.idle":"2021-05-30T19:57:51.786794Z","shell.execute_reply.started":"2021-05-30T19:57:51.782811Z","shell.execute_reply":"2021-05-30T19:57:51.785923Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_triplets = pd.read_csv(train_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')\ntest_triplets = pd.read_csv(test_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T19:57:52.713069Z","iopub.execute_input":"2021-05-30T19:57:52.713495Z","iopub.status.idle":"2021-05-30T19:57:52.827678Z","shell.execute_reply.started":"2021-05-30T19:57:52.713459Z","shell.execute_reply":"2021-05-30T19:57:52.826800Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 96\nIMG_HEIGHT = 96\n\ndef load_image(img, training):\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1\n    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n    return img\n\n\ndef load_triplets(triplet, training):\n    ids = tf.strings.split(triplet)\n    anchor = load_image(tf.io.read_file(image_path + '/' + ids[0] + '.jpg'), training)\n    truthy = load_image(tf.io.read_file(image_path + '/'  + ids[1] + '.jpg'), training)\n    falsy = load_image(tf.io.read_file(image_path + '/'  + ids[2] + '.jpg'), training)\n    if training:\n        return tf.stack([anchor, truthy, falsy], axis=0), 1\n    else:\n        return tf.stack([anchor, truthy, falsy], axis=0)\n\ndef make_dataset(dataset_filename, training=True):\n  #makes dataset from text with triplets\n  dataset = tf.data.TextLineDataset(dataset_filename)\n\n  dataset = dataset.map(\n    lambda triplet: load_triplets(triplet, training),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  return dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-30T19:57:53.638506Z","iopub.execute_input":"2021-05-30T19:57:53.638824Z","iopub.status.idle":"2021-05-30T19:57:53.649128Z","shell.execute_reply.started":"2021-05-30T19:57:53.638795Z","shell.execute_reply":"2021-05-30T19:57:53.648291Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#target_shape = (96, 96)\ntarget_shape = (200,200)\n\ndef preprocess_image(filename):\n  image_string = tf.io.read_file(image_path + '/' + filename + '.jpg')\n  image = tf.image.decode_jpeg(image_string, channels=3)\n  image = tf.image.convert_image_dtype(image, tf.float32)\n\n  image = tf.image.resize(image, target_shape)\n  return image\n\ndef preprocess_triplets(anchor, positive, negative):\n  return (preprocess_image(anchor), preprocess_image(positive), preprocess_image(negative)), 1\n  #return (preprocess_image(anchor), preprocess_image(positive), preprocess_image(negative))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:08:16.677061Z","iopub.execute_input":"2021-05-30T21:08:16.677397Z","iopub.status.idle":"2021-05-30T21:08:16.685333Z","shell.execute_reply.started":"2021-05-30T21:08:16.677367Z","shell.execute_reply":"2021-05-30T21:08:16.684430Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"anchor_images = train_triplets['anchor']\npositive_images = train_triplets['positive']\nnegative_images = train_triplets['negative']\nimage_count = len(anchor_images)\n\nanchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\npositive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\nnegative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n\ndataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\ndataset = dataset.shuffle(buffer_size=1024)\ndataset = dataset.map(preprocess_triplets)\n\n#makes a triplet of tensors of shape (96,96,3)\n\ntrain_dataset = dataset.take(round(image_count * 0.8))\nval_dataset = dataset.skip(round(image_count * 0.8))\n\ntrain_dataset = train_dataset.batch(32, drop_remainder=False)\ntrain_dataset = train_dataset.prefetch(8)\n\nval_dataset = val_dataset.batch(32, drop_remainder=False)\nval_dataset = val_dataset.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:43:12.031077Z","iopub.execute_input":"2021-05-30T20:43:12.031414Z","iopub.status.idle":"2021-05-30T20:43:12.160257Z","shell.execute_reply.started":"2021-05-30T20:43:12.031383Z","shell.execute_reply":"2021-05-30T20:43:12.159539Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"target_shape = (96,96)\ndef create_model():\n  base_cnn = tf.keras.applications.MobileNetV2(weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False)\n\n  #flatten = layers.Flatten()(base_cnn.output)\n  flatten = tf.keras.layers.GlobalAveragePooling2D()(base_cnn.output)\n  dense1 = layers.Dense(128, activation=\"relu\")(flatten)\n  output = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(dense1)\n  \n  base_cnn.trainable = False \n  embedding = Model(base_cnn.input, output, name=\"Embedding\")\n\n  anchor_input = Input(name=\"anchor\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n  positive_input = Input(name=\"positive\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n  negative_input = Input(name=\"negative\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n\n  anchor_embedding = embedding(mobilenet_v2.preprocess_input(anchor_input), training=False)\n  positive_embedding = embedding(mobilenet_v2.preprocess_input(positive_input), training=False)\n  negative_embedding = embedding(mobilenet_v2.preprocess_input(negative_input), training=False)\n\n  embeddings = tf.stack([anchor_embedding, positive_embedding, negative_embedding], axis=-1)\n  siamese_network = Model(inputs=[anchor_input, positive_input, negative_input], outputs=embeddings)\n  siamese_network.summary()\n  return siamese_network","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:42:44.502362Z","iopub.execute_input":"2021-05-30T20:42:44.502681Z","iopub.status.idle":"2021-05-30T20:42:44.513056Z","shell.execute_reply.started":"2021-05-30T20:42:44.502653Z","shell.execute_reply":"2021-05-30T20:42:44.511753Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def compute_distances(embeddings):\n  #change this to triplet output in the future\n  anchor, positive, negative = embeddings[..., 0], embeddings[..., 1], embeddings[..., 2]\n  ap_distance = tf.reduce_sum(tf.square(anchor - positive), 1)\n  an_distance = tf.reduce_sum(tf.square(anchor - negative), 1)\n  return (ap_distance, an_distance)\n\ndef triplet_loss(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  #might want to change this to L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n  return tf.reduce_mean(tf.math.softplus(ap_distance - an_distance))\n\ndef accuracy(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  return tf.reduce_mean(\n    tf.cast(tf.greater_equal(an_distance, ap_distance), tf.float32))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T19:58:00.638974Z","iopub.execute_input":"2021-05-30T19:58:00.639304Z","iopub.status.idle":"2021-05-30T19:58:00.645877Z","shell.execute_reply.started":"2021-05-30T19:58:00.639254Z","shell.execute_reply":"2021-05-30T19:58:00.644820Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=triplet_loss,\n              metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:00:45.041855Z","iopub.execute_input":"2021-05-30T20:00:45.042192Z","iopub.status.idle":"2021-05-30T20:00:46.887830Z","shell.execute_reply.started":"2021-05-30T20:00:45.042161Z","shell.execute_reply":"2021-05-30T20:00:46.887145Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nanchor (InputLayer)             [(None, 96, 96, 3)]  0                                            \n__________________________________________________________________________________________________\npositive (InputLayer)           [(None, 96, 96, 3)]  0                                            \n__________________________________________________________________________________________________\nnegative (InputLayer)           [(None, 96, 96, 3)]  0                                            \n__________________________________________________________________________________________________\ntf.math.truediv_6 (TFOpLambda)  (None, 96, 96, 3)    0           anchor[0][0]                     \n__________________________________________________________________________________________________\ntf.math.truediv_7 (TFOpLambda)  (None, 96, 96, 3)    0           positive[0][0]                   \n__________________________________________________________________________________________________\ntf.math.truediv_8 (TFOpLambda)  (None, 96, 96, 3)    0           negative[0][0]                   \n__________________________________________________________________________________________________\ntf.math.subtract_6 (TFOpLambda) (None, 96, 96, 3)    0           tf.math.truediv_6[0][0]          \n__________________________________________________________________________________________________\ntf.math.subtract_7 (TFOpLambda) (None, 96, 96, 3)    0           tf.math.truediv_7[0][0]          \n__________________________________________________________________________________________________\ntf.math.subtract_8 (TFOpLambda) (None, 96, 96, 3)    0           tf.math.truediv_8[0][0]          \n__________________________________________________________________________________________________\nEmbedding (Functional)          (None, 128)          2421952     tf.math.subtract_6[0][0]         \n                                                                 tf.math.subtract_7[0][0]         \n                                                                 tf.math.subtract_8[0][0]         \n__________________________________________________________________________________________________\ntf.stack_2 (TFOpLambda)         (None, 128, 3)       0           Embedding[0][0]                  \n                                                                 Embedding[1][0]                  \n                                                                 Embedding[2][0]                  \n==================================================================================================\nTotal params: 2,421,952\nTrainable params: 163,968\nNon-trainable params: 2,257,984\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_ds, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:01:31.638944Z","iopub.execute_input":"2021-05-30T20:01:31.639291Z","iopub.status.idle":"2021-05-30T20:09:36.289668Z","shell.execute_reply.started":"2021-05-30T20:01:31.639244Z","shell.execute_reply":"2021-05-30T20:09:36.288974Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"1488/1488 [==============================] - 485s 326ms/step - loss: 0.6931 - accuracy: 0.7899\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_test_triplets(anchor, positive, negative):\n  return (preprocess_image(anchor), preprocess_image(positive), preprocess_image(negative))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:21:44.019837Z","iopub.execute_input":"2021-05-30T20:21:44.020164Z","iopub.status.idle":"2021-05-30T20:21:44.025087Z","shell.execute_reply.started":"2021-05-30T20:21:44.020135Z","shell.execute_reply":"2021-05-30T20:21:44.024213Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"anchor_images = test_triplets['anchor']\npositive_images = test_triplets['positive']\nnegative_images = test_triplets['negative']\nimage_count = len(anchor_images)\n\nanchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\npositive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\nnegative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n\ndataset_test = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n#dataset = dataset.shuffle(buffer_size=1024)\ndataset_test = dataset_test.map(preprocess_triplets)\n\ndataset_test = dataset_test.batch(32, drop_remainder=False)\ndataset_test = dataset_test.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:09:44.241177Z","iopub.execute_input":"2021-05-30T21:09:44.241504Z","iopub.status.idle":"2021-05-30T21:09:44.289826Z","shell.execute_reply.started":"2021-05-30T21:09:44.241470Z","shell.execute_reply":"2021-05-30T21:09:44.289134Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def create_inference_model(model):\n    distance_truthy, distance_falsy = compute_distances(model.output)\n    predictions = tf.cast(tf.greater_equal(distance_falsy, distance_truthy), tf.int8)\n    return tf.keras.Model(inputs=model.inputs, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:27:46.330983Z","iopub.execute_input":"2021-05-30T20:27:46.331315Z","iopub.status.idle":"2021-05-30T20:27:46.338777Z","shell.execute_reply.started":"2021-05-30T20:27:46.331278Z","shell.execute_reply":"2021-05-30T20:27:46.337864Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"inference_model = create_inference_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:27:48.281827Z","iopub.execute_input":"2021-05-30T20:27:48.282170Z","iopub.status.idle":"2021-05-30T20:27:48.317185Z","shell.execute_reply.started":"2021-05-30T20:27:48.282141Z","shell.execute_reply":"2021-05-30T20:27:48.316505Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":" predictions = inference_model.predict(\n        dataset,\n        verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:30:23.556055Z","iopub.execute_input":"2021-05-30T20:30:23.556388Z","iopub.status.idle":"2021-05-30T20:38:02.881452Z","shell.execute_reply.started":"2021-05-30T20:30:23.556358Z","shell.execute_reply":"2021-05-30T20:38:02.880638Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"1861/1861 [==============================] - 459s 246ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:38:11.280614Z","iopub.execute_input":"2021-05-30T20:38:11.280941Z","iopub.status.idle":"2021-05-30T20:38:11.289083Z","shell.execute_reply.started":"2021-05-30T20:38:11.280912Z","shell.execute_reply":"2021-05-30T20:38:11.288209Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"[1 1 0 ... 1 0 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TESTING THE KERAS TUTORIAL STUFF","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import resnet\ntarget_shape = (200, 200)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:26.338540Z","iopub.execute_input":"2021-05-30T20:40:26.338873Z","iopub.status.idle":"2021-05-30T20:40:26.342777Z","shell.execute_reply.started":"2021-05-30T20:40:26.338846Z","shell.execute_reply":"2021-05-30T20:40:26.341813Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"base_cnn = resnet.ResNet50(\n    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n)\n\nflatten = layers.Flatten()(base_cnn.output)\ndense1 = layers.Dense(512, activation=\"relu\")(flatten)\ndense1 = layers.BatchNormalization()(dense1)\ndense2 = layers.Dense(256, activation=\"relu\")(dense1)\ndense2 = layers.BatchNormalization()(dense2)\noutput = layers.Dense(256)(dense2)\n\nembedding = Model(base_cnn.input, output, name=\"Embedding\")\n\ntrainable = False\nfor layer in base_cnn.layers:\n    if layer.name == \"conv5_block1_out\":\n        trainable = True\n    layer.trainable = trainable","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:28.859698Z","iopub.execute_input":"2021-05-30T20:40:28.860008Z","iopub.status.idle":"2021-05-30T20:40:31.058616Z","shell.execute_reply.started":"2021-05-30T20:40:28.859981Z","shell.execute_reply":"2021-05-30T20:40:31.057831Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"class DistanceLayer(layers.Layer):\n    \"\"\"\n    This layer is responsible for computing the distance between the anchor\n    embedding and the positive embedding, and the anchor embedding and the\n    negative embedding.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def call(self, anchor, positive, negative):\n        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n        return (ap_distance, an_distance)\n\n\nanchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\npositive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\nnegative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n\ndistances = DistanceLayer()(\n    embedding(resnet.preprocess_input(anchor_input)),\n    embedding(resnet.preprocess_input(positive_input)),\n    embedding(resnet.preprocess_input(negative_input)),\n)\n\nsiamese_network = Model(\n    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:34.096798Z","iopub.execute_input":"2021-05-30T20:40:34.097131Z","iopub.status.idle":"2021-05-30T20:40:35.290283Z","shell.execute_reply.started":"2021-05-30T20:40:34.097102Z","shell.execute_reply":"2021-05-30T20:40:35.289339Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"class SiameseModel(Model):\n    \"\"\"The Siamese Network model with a custom training and testing loops.\n\n    Computes the triplet loss using the three embeddings produced by the\n    Siamese Network.\n\n    The triplet loss is defined as:\n       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n    \"\"\"\n\n    def __init__(self, siamese_network, margin=0.5):\n        super(SiameseModel, self).__init__()\n        self.siamese_network = siamese_network\n        self.margin = margin\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n\n    def call(self, inputs):\n        return self.siamese_network(inputs)\n\n    def train_step(self, data):\n        # GradientTape is a context manager that records every operation that\n        # you do inside. We are using it here to compute the loss so we can get\n        # the gradients and apply them using the optimizer specified in\n        # `compile()`.\n        with tf.GradientTape() as tape:\n            loss = self._compute_loss(data)\n\n        # Storing the gradients of the loss function with respect to the\n        # weights/parameters.\n        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n\n        # Applying the gradients on the model using the specified optimizer\n        self.optimizer.apply_gradients(\n            zip(gradients, self.siamese_network.trainable_weights)\n        )\n\n        # Let's update and return the training loss metric.\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self._compute_loss(data)\n\n        # Let's update and return the loss metric.\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def _compute_loss(self, data):\n        # The output of the network is a tuple containing the distances\n        # between the anchor and the positive example, and the anchor and\n        # the negative example.\n        ap_distance, an_distance = self.siamese_network(data)\n\n        # Computing the Triplet Loss by subtracting both distances and\n        # making sure we don't get a negative value.\n        loss = ap_distance - an_distance\n        loss = tf.maximum(loss + self.margin, 0.0)\n        return loss\n\n    @property\n    def metrics(self):\n        # We need to list our metrics here so the `reset_states()` can be\n        # called automatically.\n        return [self.loss_tracker]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:38.674512Z","iopub.execute_input":"2021-05-30T20:40:38.674828Z","iopub.status.idle":"2021-05-30T20:40:38.686284Z","shell.execute_reply.started":"2021-05-30T20:40:38.674800Z","shell.execute_reply":"2021-05-30T20:40:38.685340Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"siamese_model = SiameseModel(siamese_network)\nsiamese_model.compile(optimizer=optimizers.Adam(0.0001))\nsiamese_model.fit(train_dataset, epochs=1, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:43:17.458355Z","iopub.execute_input":"2021-05-30T20:43:17.458667Z","iopub.status.idle":"2021-05-30T21:03:54.491385Z","shell.execute_reply.started":"2021-05-30T20:43:17.458640Z","shell.execute_reply":"2021-05-30T21:03:54.490675Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"1488/1488 [==============================] - 1237s 831ms/step - loss: 0.4729 - val_loss: 0.4507\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f34c67b0410>"},"metadata":{}}]},{"cell_type":"code","source":"dataset_test","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:08:36.427157Z","iopub.execute_input":"2021-05-30T21:08:36.427562Z","iopub.status.idle":"2021-05-30T21:08:36.433294Z","shell.execute_reply.started":"2021-05-30T21:08:36.427517Z","shell.execute_reply":"2021-05-30T21:08:36.432384Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"<MapDataset shapes: (((200, 200, 3), (200, 200, 3), (200, 200, 3)), ()), types: ((tf.float32, tf.float32, tf.float32), tf.int32)>"},"metadata":{}}]},{"cell_type":"code","source":"prediction = siamese_model.predict(dataset_test,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:22:17.532495Z","iopub.execute_input":"2021-05-30T21:22:17.532822Z","iopub.status.idle":"2021-05-30T21:30:10.168318Z","shell.execute_reply.started":"2021-05-30T21:22:17.532794Z","shell.execute_reply":"2021-05-30T21:30:10.167623Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"1861/1861 [==============================] - 473s 254ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"np.savetxt('predictions.txt', predictions, fmt='%i')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:31:40.447646Z","iopub.execute_input":"2021-05-30T21:31:40.447963Z","iopub.status.idle":"2021-05-30T21:31:40.584854Z","shell.execute_reply.started":"2021-05-30T21:31:40.447934Z","shell.execute_reply":"2021-05-30T21:31:40.584111Z"},"trusted":true},"execution_count":90,"outputs":[]}]}