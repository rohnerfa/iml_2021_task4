{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(42)\ntf.config.run_functions_eagerly(True)\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport shutil\n\n#from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Concatenate, BatchNormalization\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import mobilenet_v2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T14:58:23.787738Z","iopub.execute_input":"2021-05-31T14:58:23.788108Z","iopub.status.idle":"2021-05-31T14:58:29.555937Z","shell.execute_reply.started":"2021-05-31T14:58:23.788027Z","shell.execute_reply":"2021-05-31T14:58:29.555113Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_triplets_path = '../input/triplets/train_triplets.txt'\ntest_triplets_path = '../input/triplets/test_triplets.txt'\nfood_path = '/content/drive/MyDrive/ml_task4/food.zip'\nimage_path = '../input/food-img/food'","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:58:31.434700Z","iopub.execute_input":"2021-05-31T14:58:31.435053Z","iopub.status.idle":"2021-05-31T14:58:31.439455Z","shell.execute_reply.started":"2021-05-31T14:58:31.435019Z","shell.execute_reply":"2021-05-31T14:58:31.438529Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_triplets = pd.read_csv(train_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')\ntest_triplets = pd.read_csv(test_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:58:32.974427Z","iopub.execute_input":"2021-05-31T14:58:32.974805Z","iopub.status.idle":"2021-05-31T14:58:33.109334Z","shell.execute_reply.started":"2021-05-31T14:58:32.974772Z","shell.execute_reply":"2021-05-31T14:58:33.108459Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# IMG_WIDTH = 96\n# IMG_HEIGHT = 96\n\ndef load_image(img, training):\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1\n    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n    return img\n\n\ndef load_triplets(triplet, training):\n    ids = tf.strings.split(triplet)\n    anchor = load_image(tf.io.read_file(image_path + '/' + ids[0] + '.jpg'), training)\n    truthy = load_image(tf.io.read_file(image_path + '/'  + ids[1] + '.jpg'), training)\n    falsy = load_image(tf.io.read_file(image_path + '/'  + ids[2] + '.jpg'), training)\n    if training:\n        return tf.stack([anchor, truthy, falsy], axis=0), 1\n    else:\n        return tf.stack([anchor, truthy, falsy], axis=0)\n\ndef make_dataset(dataset_filename, training=True):\n  #makes dataset from text with triplets\n  dataset = tf.data.TextLineDataset(dataset_filename)\n\n  dataset = dataset.map(\n    lambda triplet: load_triplets(triplet, training),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  return dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:59:51.150836Z","iopub.execute_input":"2021-05-31T14:59:51.151182Z","iopub.status.idle":"2021-05-31T14:59:51.160702Z","shell.execute_reply.started":"2021-05-31T14:59:51.151150Z","shell.execute_reply":"2021-05-31T14:59:51.159560Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:59:53.509460Z","iopub.execute_input":"2021-05-31T14:59:53.509784Z","iopub.status.idle":"2021-05-31T14:59:53.833567Z","shell.execute_reply.started":"2021-05-31T14:59:53.509754Z","shell.execute_reply":"2021-05-31T14:59:53.832775Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:00:00.935613Z","iopub.execute_input":"2021-05-31T15:00:00.935952Z","iopub.status.idle":"2021-05-31T15:00:00.942144Z","shell.execute_reply.started":"2021-05-31T15:00:00.935922Z","shell.execute_reply":"2021-05-31T15:00:00.941244Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<ParallelMapDataset shapes: ((3, 96, 96, 3), ()), types: (tf.float32, tf.int32)>"},"metadata":{}}]},{"cell_type":"code","source":"target_shape = (224, 224)\nIMG_WIDTH = 224\nIMG_HEIGHT = 224\n#target_shape = (200,200)\n\ndef preprocess_image(filename):\n  image_string = tf.io.read_file(image_path + '/' + filename + '.jpg')\n  image = tf.image.decode_jpeg(image_string, channels=3)\n  image = tf.image.convert_image_dtype(image, tf.float32)\n\n  image = tf.image.resize(image, target_shape)\n  return image\n\ndef preprocess_triplets(anchor, positive, negative):\n    anchor = preprocess_image(anchor)\n    positive = preprocess_image(positive)\n    negative = preprocess_image(negative)\n    \n    return tf.stack([anchor, positive, negative], axis=0), 1","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:05:09.822560Z","iopub.execute_input":"2021-05-31T15:05:09.822887Z","iopub.status.idle":"2021-05-31T15:05:09.829419Z","shell.execute_reply.started":"2021-05-31T15:05:09.822856Z","shell.execute_reply":"2021-05-31T15:05:09.828579Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"anchor_images = train_triplets['anchor']\npositive_images = train_triplets['positive']\nnegative_images = train_triplets['negative']\nimage_count = len(anchor_images)\n\nanchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\npositive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\nnegative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n\ndataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\ndataset = dataset.shuffle(buffer_size=1024,reshuffle_each_iteration=True)\ndataset = dataset.map(preprocess_triplets)\n\n#makes a tuple of tensors of shape (3,96,96,3)\n\ntrain_dataset = dataset.take(round(image_count * 0.8))\nval_dataset = dataset.skip(round(image_count * 0.8))\n\ntrain_dataset = train_dataset.repeat()\ntrain_dataset = train_dataset.batch(32, drop_remainder=False)\ntrain_dataset = train_dataset.prefetch(8)\n\nval_dataset = val_dataset.batch(32, drop_remainder=False)\nval_dataset = val_dataset.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:58:45.495616Z","iopub.execute_input":"2021-05-31T14:58:45.495938Z","iopub.status.idle":"2021-05-31T14:58:48.150968Z","shell.execute_reply.started":"2021-05-31T14:58:45.495900Z","shell.execute_reply":"2021-05-31T14:58:48.150100Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:58:50.617845Z","iopub.execute_input":"2021-05-31T14:58:50.618208Z","iopub.status.idle":"2021-05-31T14:58:50.627478Z","shell.execute_reply.started":"2021-05-31T14:58:50.618172Z","shell.execute_reply":"2021-05-31T14:58:50.626297Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<MapDataset shapes: ((3, 224, 224, 3), ()), types: (tf.float32, tf.int32)>"},"metadata":{}}]},{"cell_type":"code","source":"def create_model():\n  base_cnn = tf.keras.applications.MobileNetV2(weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False)\n\n  #flatten = layers.Flatten()(base_cnn.output)\n  flatten = tf.keras.layers.GlobalAveragePooling2D()(base_cnn.output)\n  dense1 = layers.Dense(128, activation=\"relu\")(flatten)\n  output = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(dense1)\n  \n  base_cnn.trainable = False \n  embedding = Model(base_cnn.input, output, name=\"Embedding\")\n\n  inputs = Input(shape=(3, IMG_HEIGHT, IMG_WIDTH, 3))\n  anchor, positive, negative = inputs[:, 0, ...], inputs[:, 1, ...], inputs[:, 2, ...]\n#   anchor_input = Input(name=\"anchor\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n#   positive_input = Input(name=\"positive\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n#   negative_input = Input(name=\"negative\", shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n\n  anchor_embedding = embedding(mobilenet_v2.preprocess_input(anchor))\n  positive_embedding = embedding(mobilenet_v2.preprocess_input(positive))\n  negative_embedding = embedding(mobilenet_v2.preprocess_input(negative))\n\n  embeddings = tf.stack([anchor_embedding, positive_embedding, negative_embedding], axis=-1)\n  siamese_network = Model(inputs=inputs, outputs=embeddings)\n  siamese_network.summary()\n  return siamese_network","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:03:12.128703Z","iopub.execute_input":"2021-05-31T15:03:12.129057Z","iopub.status.idle":"2021-05-31T15:03:12.138462Z","shell.execute_reply.started":"2021-05-31T15:03:12.129025Z","shell.execute_reply":"2021-05-31T15:03:12.137504Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def compute_distances(embeddings):\n  #change this to triplet output in the future\n  anchor, positive, negative = embeddings[..., 0], embeddings[..., 1], embeddings[..., 2]\n  ap_distance = tf.reduce_sum(tf.square(anchor - positive), 1)\n  an_distance = tf.reduce_sum(tf.square(anchor - negative), 1)\n  return (ap_distance, an_distance)\n\ndef triplet_loss(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  #might want to change this to L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n  #softplus makes sure distance is positive, smooth approximation of ReLU\n  return tf.reduce_mean(tf.math.softplus(ap_distance - an_distance))\n\ndef accuracy(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  # equal to 1 if ap_distance <= an_distance, 0 else, calculates mean along all triplets\n  return tf.reduce_mean(\n    tf.cast(tf.greater_equal(an_distance, ap_distance), tf.float32))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:03:14.626092Z","iopub.execute_input":"2021-05-31T15:03:14.626498Z","iopub.status.idle":"2021-05-31T15:03:14.634000Z","shell.execute_reply.started":"2021-05-31T15:03:14.626462Z","shell.execute_reply":"2021-05-31T15:03:14.633125Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=triplet_loss,\n              metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:05:15.083113Z","iopub.execute_input":"2021-05-31T15:05:15.083537Z","iopub.status.idle":"2021-05-31T15:05:17.054970Z","shell.execute_reply.started":"2021-05-31T15:05:15.083500Z","shell.execute_reply":"2021-05-31T15:05:17.054153Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 3, 224, 224, 0                                            \n__________________________________________________________________________________________________\ntf.__operators__.getitem_3 (Sli (None, 224, 224, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\ntf.__operators__.getitem_4 (Sli (None, 224, 224, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\ntf.__operators__.getitem_5 (Sli (None, 224, 224, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\ntf.math.truediv_3 (TFOpLambda)  (None, 224, 224, 3)  0           tf.__operators__.getitem_3[0][0] \n__________________________________________________________________________________________________\ntf.math.truediv_4 (TFOpLambda)  (None, 224, 224, 3)  0           tf.__operators__.getitem_4[0][0] \n__________________________________________________________________________________________________\ntf.math.truediv_5 (TFOpLambda)  (None, 224, 224, 3)  0           tf.__operators__.getitem_5[0][0] \n__________________________________________________________________________________________________\ntf.math.subtract_3 (TFOpLambda) (None, 224, 224, 3)  0           tf.math.truediv_3[0][0]          \n__________________________________________________________________________________________________\ntf.math.subtract_4 (TFOpLambda) (None, 224, 224, 3)  0           tf.math.truediv_4[0][0]          \n__________________________________________________________________________________________________\ntf.math.subtract_5 (TFOpLambda) (None, 224, 224, 3)  0           tf.math.truediv_5[0][0]          \n__________________________________________________________________________________________________\nEmbedding (Functional)          (None, 128)          2421952     tf.math.subtract_3[0][0]         \n                                                                 tf.math.subtract_4[0][0]         \n                                                                 tf.math.subtract_5[0][0]         \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 128, 3)       0           Embedding[0][0]                  \n                                                                 Embedding[1][0]                  \n                                                                 Embedding[2][0]                  \n==================================================================================================\nTotal params: 2,421,952\nTrainable params: 163,968\nNon-trainable params: 2,257,984\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-31T09:07:18.299262Z","iopub.execute_input":"2021-05-31T09:07:18.299604Z","iopub.status.idle":"2021-05-31T09:07:18.307929Z","shell.execute_reply.started":"2021-05-31T09:07:18.299573Z","shell.execute_reply":"2021-05-31T09:07:18.306938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, epochs=2, steps_per_epoch = image_count // 32, validation_data = val_dataset, validation_steps=10)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:05:21.847059Z","iopub.execute_input":"2021-05-31T15:05:21.847416Z","iopub.status.idle":"2021-05-31T15:52:52.307422Z","shell.execute_reply.started":"2021-05-31T15:05:21.847383Z","shell.execute_reply":"2021-05-31T15:52:52.306537Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/2\n1859/1859 [==============================] - 1427s 765ms/step - loss: 0.6921 - accuracy: 0.5918 - val_loss: 0.6931 - val_accuracy: 0.8375\nEpoch 2/2\n1859/1859 [==============================] - 1423s 766ms/step - loss: 0.6932 - accuracy: 0.7894 - val_loss: 0.6931 - val_accuracy: 0.7906\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_test_triplets(anchor, positive, negative):\n    anchor = preprocess_image(anchor)\n    positive = preprocess_image(positive)\n    negative = preprocess_image(negative)\n    \n    return tf.stack([anchor, positive, negative], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:54:13.242556Z","iopub.execute_input":"2021-05-31T15:54:13.242884Z","iopub.status.idle":"2021-05-31T15:54:13.249137Z","shell.execute_reply.started":"2021-05-31T15:54:13.242855Z","shell.execute_reply":"2021-05-31T15:54:13.248263Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"anchor_images_test = test_triplets['anchor']\npositive_images_test = test_triplets['positive']\nnegative_images_test = test_triplets['negative']\nimage_count_test = len(anchor_images_test)\n\nanchor_dataset_test = tf.data.Dataset.from_tensor_slices(anchor_images_test)\npositive_dataset_test = tf.data.Dataset.from_tensor_slices(positive_images_test)\nnegative_dataset_test = tf.data.Dataset.from_tensor_slices(negative_images_test)\n\ndataset_test = tf.data.Dataset.zip((anchor_dataset_test, positive_dataset_test, negative_dataset_test))\n#dataset = dataset.shuffle(buffer_size=1024)\ndataset_test = dataset_test.map(preprocess_test_triplets)\n\ndataset_test = dataset_test.batch(32, drop_remainder=False)\ndataset_test = dataset_test.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:54:25.874255Z","iopub.execute_input":"2021-05-31T15:54:25.874607Z","iopub.status.idle":"2021-05-31T15:54:26.017334Z","shell.execute_reply.started":"2021-05-31T15:54:25.874575Z","shell.execute_reply":"2021-05-31T15:54:26.016510Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"dataset_test","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:54:27.801519Z","iopub.execute_input":"2021-05-31T15:54:27.801867Z","iopub.status.idle":"2021-05-31T15:54:27.810506Z","shell.execute_reply.started":"2021-05-31T15:54:27.801837Z","shell.execute_reply":"2021-05-31T15:54:27.809622Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<PrefetchDataset shapes: (None, 3, 224, 224, 3), types: tf.float32>"},"metadata":{}}]},{"cell_type":"code","source":"def create_inference_model(model):\n    ap_distance, an_distance = compute_distances(model.output)\n    predictions = tf.cast(tf.greater_equal(an_distance, ap_distance), tf.int8)\n    return tf.keras.Model(inputs=model.inputs, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:05:23.235465Z","iopub.execute_input":"2021-05-31T16:05:23.235801Z","iopub.status.idle":"2021-05-31T16:05:23.240133Z","shell.execute_reply.started":"2021-05-31T16:05:23.235770Z","shell.execute_reply":"2021-05-31T16:05:23.239366Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"inference_model = create_inference_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:55:04.348998Z","iopub.execute_input":"2021-05-31T15:55:04.349336Z","iopub.status.idle":"2021-05-31T15:55:04.386808Z","shell.execute_reply.started":"2021-05-31T15:55:04.349285Z","shell.execute_reply":"2021-05-31T15:55:04.386051Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":" predictions = inference_model.predict(\n        dataset_test,\n        verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:55:22.197240Z","iopub.execute_input":"2021-05-31T15:55:22.197629Z","iopub.status.idle":"2021-05-31T16:03:34.634849Z","shell.execute_reply.started":"2021-05-31T15:55:22.197596Z","shell.execute_reply":"2021-05-31T16:03:34.634044Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1861/1861 [==============================] - 492s 264ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# predictions_fixed = 1-predictions","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:07:22.744052Z","iopub.execute_input":"2021-05-31T16:07:22.744387Z","iopub.status.idle":"2021-05-31T16:07:22.748785Z","shell.execute_reply.started":"2021-05-31T16:07:22.744355Z","shell.execute_reply":"2021-05-31T16:07:22.747691Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Create submission file\n\nnp.savetxt('submission.txt', predictions, fmt='%d')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:07:57.294100Z","iopub.execute_input":"2021-05-31T16:07:57.294457Z","iopub.status.idle":"2021-05-31T16:07:57.419266Z","shell.execute_reply.started":"2021-05-31T16:07:57.294423Z","shell.execute_reply":"2021-05-31T16:07:57.418390Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"TESTING THE KERAS TUTORIAL STUFF","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.applications import resnet\n# target_shape = (200, 200)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:26.33854Z","iopub.execute_input":"2021-05-30T20:40:26.338873Z","iopub.status.idle":"2021-05-30T20:40:26.342777Z","shell.execute_reply.started":"2021-05-30T20:40:26.338846Z","shell.execute_reply":"2021-05-30T20:40:26.341813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_cnn = resnet.ResNet50(\n#     weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n# )\n\n# flatten = layers.Flatten()(base_cnn.output)\n# dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n# dense1 = layers.BatchNormalization()(dense1)\n# dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n# dense2 = layers.BatchNormalization()(dense2)\n# output = layers.Dense(256)(dense2)\n\n# embedding = Model(base_cnn.input, output, name=\"Embedding\")\n\n# trainable = False\n# for layer in base_cnn.layers:\n#     if layer.name == \"conv5_block1_out\":\n#         trainable = True\n#     layer.trainable = trainable","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:28.859698Z","iopub.execute_input":"2021-05-30T20:40:28.860008Z","iopub.status.idle":"2021-05-30T20:40:31.058616Z","shell.execute_reply.started":"2021-05-30T20:40:28.859981Z","shell.execute_reply":"2021-05-30T20:40:31.057831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class DistanceLayer(layers.Layer):\n#     \"\"\"\n#     This layer is responsible for computing the distance between the anchor\n#     embedding and the positive embedding, and the anchor embedding and the\n#     negative embedding.\n#     \"\"\"\n\n#     def __init__(self, **kwargs):\n#         super().__init__(**kwargs)\n\n#     def call(self, anchor, positive, negative):\n#         ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n#         an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n#         return (ap_distance, an_distance)\n\n\n# anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n# positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n# negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n\n# distances = DistanceLayer()(\n#     embedding(resnet.preprocess_input(anchor_input)),\n#     embedding(resnet.preprocess_input(positive_input)),\n#     embedding(resnet.preprocess_input(negative_input)),\n# )\n\n# siamese_network = Model(\n#     inputs=[anchor_input, positive_input, negative_input], outputs=distances\n# )","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:34.096798Z","iopub.execute_input":"2021-05-30T20:40:34.097131Z","iopub.status.idle":"2021-05-30T20:40:35.290283Z","shell.execute_reply.started":"2021-05-30T20:40:34.097102Z","shell.execute_reply":"2021-05-30T20:40:35.289339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class SiameseModel(Model):\n#     \"\"\"The Siamese Network model with a custom training and testing loops.\n\n#     Computes the triplet loss using the three embeddings produced by the\n#     Siamese Network.\n\n#     The triplet loss is defined as:\n#        L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n#     \"\"\"\n\n#     def __init__(self, siamese_network, margin=0.5):\n#         super(SiameseModel, self).__init__()\n#         self.siamese_network = siamese_network\n#         self.margin = margin\n#         self.loss_tracker = metrics.Mean(name=\"loss\")\n\n#     def call(self, inputs):\n#         return self.siamese_network(inputs)\n\n#     def train_step(self, data):\n#         # GradientTape is a context manager that records every operation that\n#         # you do inside. We are using it here to compute the loss so we can get\n#         # the gradients and apply them using the optimizer specified in\n#         # `compile()`.\n#         with tf.GradientTape() as tape:\n#             loss = self._compute_loss(data)\n\n#         # Storing the gradients of the loss function with respect to the\n#         # weights/parameters.\n#         gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n\n#         # Applying the gradients on the model using the specified optimizer\n#         self.optimizer.apply_gradients(\n#             zip(gradients, self.siamese_network.trainable_weights)\n#         )\n\n#         # Let's update and return the training loss metric.\n#         self.loss_tracker.update_state(loss)\n#         return {\"loss\": self.loss_tracker.result()}\n\n#     def test_step(self, data):\n#         loss = self._compute_loss(data)\n\n#         # Let's update and return the loss metric.\n#         self.loss_tracker.update_state(loss)\n#         return {\"loss\": self.loss_tracker.result()}\n\n#     def _compute_loss(self, data):\n#         # The output of the network is a tuple containing the distances\n#         # between the anchor and the positive example, and the anchor and\n#         # the negative example.\n#         ap_distance, an_distance = self.siamese_network(data)\n\n#         # Computing the Triplet Loss by subtracting both distances and\n#         # making sure we don't get a negative value.\n#         loss = ap_distance - an_distance\n#         loss = tf.maximum(loss + self.margin, 0.0)\n#         return loss\n\n#     @property\n#     def metrics(self):\n#         # We need to list our metrics here so the `reset_states()` can be\n#         # called automatically.\n#         return [self.loss_tracker]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:40:38.674512Z","iopub.execute_input":"2021-05-30T20:40:38.674828Z","iopub.status.idle":"2021-05-30T20:40:38.686284Z","shell.execute_reply.started":"2021-05-30T20:40:38.6748Z","shell.execute_reply":"2021-05-30T20:40:38.68534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# siamese_model = SiameseModel(siamese_network)\n# siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n# siamese_model.fit(train_dataset, epochs=1, validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T20:43:17.458355Z","iopub.execute_input":"2021-05-30T20:43:17.458667Z","iopub.status.idle":"2021-05-30T21:03:54.491385Z","shell.execute_reply.started":"2021-05-30T20:43:17.45864Z","shell.execute_reply":"2021-05-30T21:03:54.490675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset_test","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:08:36.427157Z","iopub.execute_input":"2021-05-30T21:08:36.427562Z","iopub.status.idle":"2021-05-30T21:08:36.433294Z","shell.execute_reply.started":"2021-05-30T21:08:36.427517Z","shell.execute_reply":"2021-05-30T21:08:36.432384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction = siamese_model.predict(dataset_test,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:22:17.532495Z","iopub.execute_input":"2021-05-30T21:22:17.532822Z","iopub.status.idle":"2021-05-30T21:30:10.168318Z","shell.execute_reply.started":"2021-05-30T21:22:17.532794Z","shell.execute_reply":"2021-05-30T21:30:10.167623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.savetxt('predictions.txt', predictions, fmt='%i')\n# Create submission file\ntest_y_fixed = np.where(test_y < 0.5, 0, 1)\n\nnp.savetxt('submission.txt', test_y_fixed, fmt='%d')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T21:31:40.447646Z","iopub.execute_input":"2021-05-30T21:31:40.447963Z","iopub.status.idle":"2021-05-30T21:31:40.584854Z","shell.execute_reply.started":"2021-05-30T21:31:40.447934Z","shell.execute_reply":"2021-05-30T21:31:40.584111Z"},"trusted":true},"execution_count":null,"outputs":[]}]}