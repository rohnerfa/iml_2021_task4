{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(42)\ntf.config.run_functions_eagerly(True)\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport shutil\n\n#from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Concatenate, BatchNormalization\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import mobilenet_v2\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T20:16:38.795153Z","iopub.execute_input":"2021-06-02T20:16:38.795482Z","iopub.status.idle":"2021-06-02T20:16:43.913629Z","shell.execute_reply.started":"2021-06-02T20:16:38.795412Z","shell.execute_reply":"2021-06-02T20:16:43.912798Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_triplets_path = '../input/triplets/train_triplets.txt'\ntest_triplets_path = '../input/triplets/test_triplets.txt'\nfood_path = '/content/drive/MyDrive/ml_task4/food.zip'\nimage_path = '../input/food-img/food'","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:43.915014Z","iopub.execute_input":"2021-06-02T20:16:43.915320Z","iopub.status.idle":"2021-06-02T20:16:43.922641Z","shell.execute_reply.started":"2021-06-02T20:16:43.915286Z","shell.execute_reply":"2021-06-02T20:16:43.921743Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# My Implementation","metadata":{}},{"cell_type":"code","source":"train_triplets = pd.read_csv(train_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')\ntest_triplets = pd.read_csv(test_triplets_path, delim_whitespace=True, header=None, names =['anchor','positive','negative'], dtype='str')\n\ntrain_samples, val_samples = train_test_split(train_triplets, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:46.341448Z","iopub.execute_input":"2021-06-02T20:16:46.341761Z","iopub.status.idle":"2021-06-02T20:16:46.498022Z","shell.execute_reply.started":"2021-06-02T20:16:46.341732Z","shell.execute_reply":"2021-06-02T20:16:46.497228Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"target_shape = (224, 224)\nIMG_WIDTH = 224\nIMG_HEIGHT = 224\n\n#target_shape = (299, 299)\n#IMG_WIDTH = 299\n#IMG_HEIGHT = 299\n\ndef preprocess_image(filename,training=True):\n    image_string = tf.io.read_file(image_path + '/' + filename + '.jpg')\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = image / 127.5 - 1\n    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n    if training:\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n    return image\n\ndef preprocess_triplets_train(anchor, positive, negative):\n    anchor_img = preprocess_image(anchor)\n    positive_img = preprocess_image(positive)\n    negative_img = preprocess_image(negative)\n    \n    return tf.stack([anchor_img, positive_img, negative_img], axis=0), 1\n\ndef preprocess_triplets_test(anchor, positive, negative):\n    anchor_img = preprocess_image(anchor, training=False)\n    positive_img = preprocess_image(positive, training=False)\n    negative_img = preprocess_image(negative, training=False)\n    \n    return tf.stack([anchor_img, positive_img, negative_img], axis=0)\n\ndef generate_dataset(triplet_df, training=True):\n    anchor_images = triplet_df['anchor']\n    positive_images = triplet_df['positive']\n    negative_images = triplet_df['negative']\n\n    anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n    positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n    negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n\n    dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n    if training:\n        dataset = dataset.map(preprocess_triplets_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    else:\n        dataset = dataset.map(preprocess_triplets_test,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:49.033356Z","iopub.execute_input":"2021-06-02T20:16:49.033694Z","iopub.status.idle":"2021-06-02T20:16:49.045530Z","shell.execute_reply.started":"2021-06-02T20:16:49.033664Z","shell.execute_reply":"2021-06-02T20:16:49.044447Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    base_cnn = tf.keras.applications.InceptionResNetV2(weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False)\n    #base_cnn = tf.keras.applications.MobileNetV2(weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False)\n    base_cnn.trainable = False \n\n#   #flatten = layers.Flatten()(base_cnn.output)\n    flatten = tf.keras.layers.GlobalAveragePooling2D()(base_cnn.output)\n    dense1 = layers.Dense(128, activation=\"relu\")(flatten)\n    output = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(dense1)\n  \n    embedding = Model(inputs = base_cnn.input, outputs = output, name=\"Embedding\")\n    \n    \n    inputs = tf.keras.Input(shape=(3, IMG_HEIGHT, IMG_WIDTH, 3))\n    anchor, positive, negative = inputs[:, 0, ...], inputs[:, 1, ...], inputs[:, 2, ...]\n\n    anchor_embedding = embedding(anchor)\n    positive_embedding = embedding(positive)\n    negative_embedding = embedding(negative)\n\n    embeddings = tf.stack([anchor_embedding, positive_embedding, negative_embedding], axis=-1)\n    siamese_network = Model(inputs=inputs, outputs=embeddings)\n    siamese_network.summary()\n    return siamese_network","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:51.218404Z","iopub.execute_input":"2021-06-02T20:16:51.218732Z","iopub.status.idle":"2021-06-02T20:16:51.227551Z","shell.execute_reply.started":"2021-06-02T20:16:51.218703Z","shell.execute_reply":"2021-06-02T20:16:51.226322Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def compute_distances(embeddings):\n  #change this to triplet output in the future\n  anchor, positive, negative = embeddings[..., 0], embeddings[..., 1], embeddings[..., 2]\n  ap_distance = tf.reduce_sum(tf.square(anchor - positive), 1)\n  an_distance = tf.reduce_sum(tf.square(anchor - negative), 1)\n  return (ap_distance, an_distance)\n\ndef triplet_loss(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  #might want to change this to L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n  #softplus makes sure distance is positive, smooth approximation of ReLU\n  return tf.reduce_mean(tf.math.softplus(ap_distance - an_distance))\n\ndef accuracy(_, embeddings):\n  ap_distance, an_distance = compute_distances(embeddings)\n  # equal to 1 if ap_distance <= an_distance, 0 else, calculates mean along all triplets\n  return tf.reduce_mean(\n    tf.cast(tf.greater_equal(an_distance, ap_distance), tf.float32))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:53.741315Z","iopub.execute_input":"2021-06-02T20:16:53.741640Z","iopub.status.idle":"2021-06-02T20:16:53.747721Z","shell.execute_reply.started":"2021-06-02T20:16:53.741609Z","shell.execute_reply":"2021-06-02T20:16:53.746920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=triplet_loss,\n              metrics=[accuracy])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:16:56.226333Z","iopub.execute_input":"2021-06-02T20:16:56.226647Z","iopub.status.idle":"2021-06-02T20:17:09.524656Z","shell.execute_reply.started":"2021-06-02T20:16:56.226618Z","shell.execute_reply":"2021-06-02T20:17:09.523902Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219062272/219055592 [==============================] - 3s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 3, 224, 224, 0                                            \n__________________________________________________________________________________________________\ntf.__operators__.getitem (Slici (None, 224, 224, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\ntf.__operators__.getitem_1 (Sli (None, 224, 224, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\ntf.__operators__.getitem_2 (Sli (None, 224, 224, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nEmbedding (Functional)          (None, 128)          54533472    tf.__operators__.getitem[0][0]   \n                                                                 tf.__operators__.getitem_1[0][0] \n                                                                 tf.__operators__.getitem_2[0][0] \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 128, 3)       0           Embedding[0][0]                  \n                                                                 Embedding[1][0]                  \n                                                                 Embedding[2][0]                  \n==================================================================================================\nTotal params: 54,533,472\nTrainable params: 196,736\nNon-trainable params: 54,336,736\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = generate_dataset(train_samples)\nval_dataset = generate_dataset(val_samples)\ntrain_image_count = train_samples.shape[0]\n\ntrain_dataset = train_dataset.shuffle(1024, reshuffle_each_iteration=True).repeat().batch(32)\ntrain_dataset = train_dataset.prefetch(8)\n\nval_dataset = val_dataset.batch(32)\nval_dataset = val_dataset.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:17:13.546377Z","iopub.execute_input":"2021-06-02T20:17:13.546696Z","iopub.status.idle":"2021-06-02T20:17:13.904515Z","shell.execute_reply.started":"2021-06-02T20:17:13.546667Z","shell.execute_reply":"2021-06-02T20:17:13.903689Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_path = \"training_1/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:17:18.544981Z","iopub.execute_input":"2021-06-02T20:17:18.545294Z","iopub.status.idle":"2021-06-02T20:17:18.551121Z","shell.execute_reply.started":"2021-06-02T20:17:18.545265Z","shell.execute_reply":"2021-06-02T20:17:18.548651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, steps_per_epoch=train_image_count // 32,epochs=3,validation_data=val_dataset,validation_steps=10,callbacks=[cp_callback])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:17:23.330267Z","iopub.execute_input":"2021-06-02T20:17:23.330585Z","iopub.status.idle":"2021-06-02T22:02:40.252674Z","shell.execute_reply.started":"2021-06-02T20:17:23.330556Z","shell.execute_reply":"2021-06-02T22:02:40.251824Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/3\n1487/1487 [==============================] - 2123s 1s/step - loss: 0.5965 - accuracy: 0.6818 - val_loss: 0.5531 - val_accuracy: 0.7250\n\nEpoch 00001: saving model to training_1/cp.ckpt\nEpoch 2/3\n1487/1487 [==============================] - 2093s 1s/step - loss: 0.5668 - accuracy: 0.7125 - val_loss: 0.5418 - val_accuracy: 0.7469\n\nEpoch 00002: saving model to training_1/cp.ckpt\nEpoch 3/3\n1487/1487 [==============================] - 2098s 1s/step - loss: 0.5705 - accuracy: 0.7110 - val_loss: 0.5526 - val_accuracy: 0.7063\n\nEpoch 00003: saving model to training_1/cp.ckpt\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights('../input/4epochs/cp.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:46:52.334809Z","iopub.execute_input":"2021-06-02T13:46:52.335137Z","iopub.status.idle":"2021-06-02T13:46:53.211222Z","shell.execute_reply.started":"2021-06-02T13:46:52.335108Z","shell.execute_reply":"2021-06-02T13:46:53.210214Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7faf344a0250>"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(checkpoint_dir, 'zip', checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:03:17.657031Z","iopub.execute_input":"2021-06-02T22:03:17.657344Z","iopub.status.idle":"2021-06-02T22:03:27.978316Z","shell.execute_reply.started":"2021-06-02T22:03:17.657317Z","shell.execute_reply":"2021-06-02T22:03:27.977460Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/training_1.zip'"},"metadata":{}}]},{"cell_type":"code","source":"def create_inference_model(model):\n    ap_distance, an_distance = compute_distances(model.output)\n    predictions = tf.cast(tf.greater_equal(an_distance, ap_distance), tf.int8)\n    return tf.keras.Model(inputs=model.inputs, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:04:13.156313Z","iopub.execute_input":"2021-06-02T22:04:13.156626Z","iopub.status.idle":"2021-06-02T22:04:13.160947Z","shell.execute_reply.started":"2021-06-02T22:04:13.156597Z","shell.execute_reply":"2021-06-02T22:04:13.160102Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"inference_model = create_inference_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:04:14.224739Z","iopub.execute_input":"2021-06-02T22:04:14.225117Z","iopub.status.idle":"2021-06-02T22:04:14.261847Z","shell.execute_reply.started":"2021-06-02T22:04:14.225089Z","shell.execute_reply":"2021-06-02T22:04:14.261098Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_dataset = generate_dataset(test_triplets, training=False).batch(256).prefetch(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:04:16.859508Z","iopub.execute_input":"2021-06-02T22:04:16.859850Z","iopub.status.idle":"2021-06-02T22:04:16.951774Z","shell.execute_reply.started":"2021-06-02T22:04:16.859818Z","shell.execute_reply":"2021-06-02T22:04:16.951036Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":" predictions = inference_model.predict(\n        test_dataset,\n        verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:04:21.925412Z","iopub.execute_input":"2021-06-02T22:04:21.925729Z","iopub.status.idle":"2021-06-02T22:12:59.906765Z","shell.execute_reply.started":"2021-06-02T22:04:21.925699Z","shell.execute_reply":"2021-06-02T22:12:59.905962Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"233/233 [==============================] - 518s 2s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:13:10.165197Z","iopub.execute_input":"2021-06-02T22:13:10.165524Z","iopub.status.idle":"2021-06-02T22:13:10.170653Z","shell.execute_reply.started":"2021-06-02T22:13:10.165491Z","shell.execute_reply":"2021-06-02T22:13:10.169536Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[1 0 0 ... 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create submission file\n\nnp.savetxt('submission.txt', predictions, fmt='%d')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T22:13:14.078544Z","iopub.execute_input":"2021-06-02T22:13:14.078956Z","iopub.status.idle":"2021-06-02T22:13:14.200080Z","shell.execute_reply.started":"2021-06-02T22:13:14.078914Z","shell.execute_reply":"2021-06-02T22:13:14.199294Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}